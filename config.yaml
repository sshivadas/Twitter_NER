# config.yaml

# === General Settings ===
seed: 42
device: "cuda"  # or "cpu"
model_type: "bilstm-crf"  # options: "bilstm-crf", "bert", "gensim"

# === Data Parameters ===
data:
  train_path: "data/wnut 16.txt.conll"
  test_path: "data/wnut 16test.txt.conll"
  max_seq_length: 128
  lowercase: true
  padding: "post"
  oov_token: "<UNK>"
  tokenizer: "bert-base-uncased"  # used only if model_type == "bert"

# === Model: BiLSTM-CRF ===
bilstm_crf:
  embedding_dim: 100
  hidden_dim: 256
  dropout: 0.5
  use_pretrained_embeddings: true
  embeddings_path: "models/word2vec.bin"  # Only if use_pretrained_embeddings is true
  bidirectional: true

# === Model: BERT ===
bert:
  pretrained_model_name: "bert-base-uncased"
  fine_tune: true
  dropout: 0.3
  use_crf: true

# === Model: Gensim Word2Vec Training (Optional) ===
gensim:
  size: 100
  window: 5
  min_count: 2
  workers: 4
  sg: 1  # 1 = skip-gram, 0 = CBOW
  save_path: "models/word2vec.bin"

# === Training Parameters ===
training:
  epochs: 10
  batch_size: 32
  learning_rate: 0.001  # for BERT, often 3e-5 is used
  optimizer: "adam"
  weight_decay: 0.0
  scheduler: "step"
  step_size: 3
  gamma: 0.1
  gradient_clip: 5.0

# === Evaluation ===
evaluation:
  eval_batch_size: 64
  metrics: ["precision", "recall", "f1"]

# === Output Directories ===
output:
  model_dir: "models/"
  log_dir: "logs/"
  predictions_file: "outputs/predictions.csv"
